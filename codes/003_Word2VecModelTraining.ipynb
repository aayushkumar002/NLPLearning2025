{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61b4935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f41a6173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec,keyedvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9acf0c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3acd15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences: 145020\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from nltk import sent_tokenize\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "story = []\n",
    "path = r'D:\\pyproj\\venv\\codes\\NLPLearning2025\\files'\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    file_path = os.path.join(path, file)\n",
    "\n",
    "    if os.path.isfile(file_path) and file.endswith(\".txt\"):\n",
    "        with open(file_path, 'r', encoding='cp1252') as f:\n",
    "            data = f.read()\n",
    "            for sentence in sent_tokenize(data):\n",
    "                story.append(simple_preprocess(sentence))\n",
    "\n",
    "print(f\"Total sentences: {len(story)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3866ea8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['game',\n",
       "  'of',\n",
       "  'thrones',\n",
       "  'book',\n",
       "  'one',\n",
       "  'of',\n",
       "  'song',\n",
       "  'of',\n",
       "  'ice',\n",
       "  'and',\n",
       "  'fire',\n",
       "  'by',\n",
       "  'george',\n",
       "  'martin',\n",
       "  'prologue',\n",
       "  'we',\n",
       "  'should',\n",
       "  'start',\n",
       "  'back',\n",
       "  'gared',\n",
       "  'urged',\n",
       "  'as',\n",
       "  'the',\n",
       "  'woods',\n",
       "  'began',\n",
       "  'to',\n",
       "  'grow',\n",
       "  'dark',\n",
       "  'around',\n",
       "  'them'],\n",
       " ['the', 'wildlings', 'are', 'dead'],\n",
       " ['do', 'the', 'dead', 'frighten', 'you'],\n",
       " ['ser',\n",
       "  'waymar',\n",
       "  'royce',\n",
       "  'asked',\n",
       "  'with',\n",
       "  'just',\n",
       "  'the',\n",
       "  'hint',\n",
       "  'of',\n",
       "  'smile'],\n",
       " ['gared', 'did', 'not', 'rise', 'to', 'the', 'bait']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story[0:5]  # Display the first 5 preprocessed sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
